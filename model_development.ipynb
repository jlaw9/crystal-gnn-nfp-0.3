{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7f50a1ab-02e5-4efe-961a-5e76df9b5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d121dd32-d316-47de-acef-1baf4b72429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import nfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from nfp.layers import RBFExpansion\n",
    "from nfp.preprocessing.crystal_preprocessor import PymatgenPreprocessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d76285a-73fe-4561-8d26-da7be047526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_dir = Path(\"/projects/rlmolecule/pstjohn/crystal_inputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "587ef07c-290c-443f-8d8d-a3bdbdbb6c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9c26837c214546b986ea4bd2565a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_pickle(Path(inputs_dir, \"20211227_all_data.p\"))\n",
    "preprocessor = PymatgenPreprocessor()\n",
    "preprocessor.from_json(Path(inputs_dir, \"20211227_preprocessor.json\"))\n",
    "\n",
    "train, valid = train_test_split(data, test_size=2000, random_state=1)\n",
    "valid, test = train_test_split(valid, test_size=0.5)\n",
    "\n",
    "def calculate_output_bias(train):\n",
    "    \"\"\" We can get a reasonable guess for the output bias by just assuming the crystal's\n",
    "     energy is a linear sum over it's element types \"\"\"\n",
    "    # This just converts to a count of each element by crystal\n",
    "    site_counts = train.inputs.progress_apply(\n",
    "        lambda x: pd.Series(Counter(x[\"site\"]))\n",
    "    ).fillna(0)\n",
    "    # Linear regression assumes a sum, while we average over sites in the neural network.\n",
    "    # Here, we make the regression target the total energy, not the site-averaged energy\n",
    "    num_sites = site_counts.sum(1)\n",
    "    total_energies = train[\"energyperatom\"] * num_sites\n",
    "\n",
    "    # Do the least-squares regression, and stack on zeros for the mask and unknown tokens\n",
    "    output_bias = np.linalg.lstsq(site_counts, total_energies, rcond=None)[0]\n",
    "    output_bias = np.hstack([np.zeros(2), output_bias])\n",
    "    return output_bias\n",
    "\n",
    "\n",
    "# Calculate an initial guess for the output bias\n",
    "output_bias = calculate_output_bias(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b8d733f-0f9a-42e8-a4a5-68be0e68ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = np.concatenate(data.inputs.apply(lambda x: x['distance']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f6e5087-5e6e-46bb-ac4b-decf69d09aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, x = np.histogram(all_dists, range=(1, 7), bins=1000)\n",
    "plt.plot(x[1:], y)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cad951da-c4e7-4354-9066-3b41751ba19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(split):\n",
    "    return (\n",
    "        tf.data.Dataset.from_generator(\n",
    "            lambda: ((row.inputs, row.energyperatom) for _, row in split.iterrows()),\n",
    "            output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\n",
    "        .cache()\n",
    "        .shuffle(buffer_size=len(split))    \n",
    "        .padded_batch(batch_size=128, padding_values=(preprocessor.padding_values, tf.constant(np.nan, dtype=tf.float32)))\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93a53af3-5f31-4e80-bcf4-a4ac22e0e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81edf77f-bffc-4f55-a129-5128c4b1c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=1000, stratify=data.comp_type)\n",
    "valid, test = train_test_split(valid, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc7ed34f-9299-44ed-b797-2e909de8a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b18e9d64-8033-43a2-a47d-c4e182988c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 48 and the array at index 7 has size 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-40b3b3c89dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 48 and the array at index 7 has size 40"
     ]
    }
   ],
   "source": [
    "np.concatenate(site_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "158f29b1-288d-4319-98a1-d8732f26b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33c0025a-2e7f-4b2f-bd9a-790d250444bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51492</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31731</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2    3    4    5    6     7    8    9    10   11  ...   20   21    22  \\\n",
       "37016  0.0  6.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "12951  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  2.0  0.0  ...  0.0  0.0  10.0   \n",
       "43576  0.0  0.0  0.0  0.0  2.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "51492  4.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "31731  6.0  0.0  0.0  0.0  0.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "...    ...  ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "25156  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  16.0   \n",
       "9893   0.0  0.0  0.0  0.0  0.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "38346  0.0  6.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "39537  0.0  0.0  0.0  0.0  0.0   2.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   0.0   \n",
       "27253  0.0  6.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   2.0   \n",
       "\n",
       "        23   24   25   26   27    28   29  \n",
       "37016  0.0  2.0  2.0  0.0  0.0   4.0  0.0  \n",
       "12951  4.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "43576  2.0  0.0  0.0  0.0  0.0  10.0  0.0  \n",
       "51492  0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "31731  0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...   ...  ...  \n",
       "25156  0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "9893   0.0  0.0  0.0  8.0  0.0   0.0  0.0  \n",
       "38346  0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "39537  0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "27253  0.0  6.0  0.0  0.0  0.0   0.0  0.0  \n",
       "\n",
       "[100 rows x 28 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(100).inputs.apply(lambda x: pd.Series(Counter(x['site']))).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edc495e6-909c-49f7-a865-eac24a96c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f0a0b7c-2ed3-4ef9-8a70-a029059e9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f7ca1901904feca86ea414d71f0251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This just converts to a count of each element by crystal\n",
    "site_counts = train.inputs.progress_apply(lambda x: pd.Series(Counter(x['site']))).fillna(0)\n",
    "# Linear regression assumes a sum, while we average over sites in the neural network.\n",
    "# Here, we make the regression target the total energy, not the site-averaged energy\n",
    "num_sites = site_counts.sum(1)\n",
    "total_energies = train['energyperatom'] * num_sites\n",
    "\n",
    "# Do the least-squares regression, and stack on zeros for the mask and unknown tokens\n",
    "output_bias = np.linalg.lstsq(site_counts, total_energies, rcond=None)[0]\n",
    "output_bias = np.hstack([np.zeros(2), output_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db7ddf31-b60f-4a15-b934-25f460829090",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_linear = (site_counts @ np.linalg.lstsq(site_counts, total_energies, rcond=None)[0]) / num_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29ee304d-ed4f-4d97-b682-1713c1b5953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e191efe7-f756-4cb9-93f6-6938c5c1d5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2774262841351785"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(pred_linear, train['energyperatom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b242e7ea-6ca1-433e-8d5c-c025ce44cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026061354976255474"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3225120) / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b9a648c-8ce0-49a0-b7c3-a2e375933943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,  -0.35386067,  -5.04603822,\n",
       "        -5.82722222,  -3.4960666 ,  -1.92183528,  -7.95527783,\n",
       "         0.78714291,  -7.87406679,  -2.86423775, -11.05412017,\n",
       "        -0.96718567,  -3.25319527,  -2.09999966,  -9.34459072,\n",
       "        -3.00677933,  -8.39919494,  -1.58762715,  -8.79313123,\n",
       "        -5.76760915,  -2.83021062,  -4.98811183,  -7.88154747,\n",
       "        -5.00972514,  -3.42817016,  -7.48886232,  -6.60338796,\n",
       "        -2.8215705 ,  -8.87809633])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca677c60-e123-4a38-b137-229654c819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "site_class = layers.Input(shape=[None], dtype=tf.int64, name=\"site\")\n",
    "distances = layers.Input(shape=[None], dtype=tf.float32, name=\"distance\")\n",
    "connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name=\"connectivity\")\n",
    "input_tensors = [site_class, distances, connectivity]\n",
    "\n",
    "embed_dimension = 256\n",
    "num_messages = 6\n",
    "\n",
    "atom_state = layers.Embedding(\n",
    "    preprocessor.site_classes, embed_dimension, name=\"site_embedding\", mask_zero=True\n",
    ")(site_class)\n",
    "\n",
    "atom_mean = layers.Embedding(\n",
    "    preprocessor.site_classes,\n",
    "    1,\n",
    "    name=\"site_mean\",\n",
    "    mask_zero=True,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(output_bias),\n",
    ")(site_class)\n",
    "\n",
    "rbf_distance = RBFExpansion(\n",
    "    dimension=128, init_max_distance=7, init_gap=30, trainable=True\n",
    ")(distances)\n",
    "\n",
    "bond_state = layers.Dense(embed_dimension)(rbf_distance)\n",
    "\n",
    "for _ in range(num_messages):\n",
    "    new_bond_state = nfp.EdgeUpdate()([atom_state, bond_state, connectivity])\n",
    "    bond_state = layers.Add()([bond_state, new_bond_state])\n",
    "    new_atom_state = nfp.NodeUpdate()([atom_state, bond_state, connectivity])\n",
    "    atom_state = layers.Add()([atom_state, new_atom_state])\n",
    "\n",
    "# Reduce the atom state vector to a single energy prediction\n",
    "atom_state = layers.Dense(\n",
    "    1,\n",
    "    name=\"site_energy_offset\",\n",
    "    kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "        mean=0.0, stddev=1e-6, seed=None\n",
    "    ),\n",
    ")(atom_state)\n",
    "\n",
    "# Add this 'offset' prediction to the learned mean energy for the given element type\n",
    "atom_state = layers.Add(name=\"add_energy_offset\")([atom_state, atom_mean])\n",
    "\n",
    "# Calculate a final mean energy per atom\n",
    "out = tf.keras.layers.GlobalAveragePooling1D()(atom_state)\n",
    "\n",
    "model = tf.keras.Model(input_tensors, [out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57890319-674e-447a-9461-8ed59d89ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "        tf.data.Dataset.from_generator(\n",
    "            lambda: ((row.inputs, row.energyperatom) for _, row in train.iterrows()),\n",
    "            output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\n",
    "        .cache()\n",
    "        .padded_batch(batch_size=128, padding_values=(preprocessor.padding_values, tf.constant(np.nan, dtype=tf.float32)))\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "177fb7f0-980d-4097-a4b2-6e835e6fcace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19/Unknown - 5s 164ms/step - loss: 0.3614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-cae2e754cb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/rlmol/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mae\", optimizer='adam')\n",
    "model.evaluate(train_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f8eac-9bd1-424d-8212-980e77322c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['energyperatom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bfc49-0858-4488-b79d-90ee0b122bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
